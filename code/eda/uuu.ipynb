{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba65a5-c233-4df5-a02f-29d946fbba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from albumentations.augmentations.transforms import RandomResizedCrop\n",
    "\n",
    "# sys.path.insert(0, '/opt/ml/code/yolov4')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "from dataset import RecycleTrashDataset, collater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9c8fb-8389-49fc-b074-84512c12b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5cb33-8a8a-4d5f-ab7c-8f7faf24a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize function\n",
    "def denormalize_image(image, mean, std):\n",
    "    img_cp = image.copy()\n",
    "    img_cp *= std\n",
    "    img_cp += mean\n",
    "    img_cp *= 255.0\n",
    "    img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "# Class index\n",
    "CLASSES = [\n",
    "    \"UNKNOWN\",\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    "]\n",
    "\n",
    "# bbox Color\n",
    "COLORS = [\n",
    "    (39, 129, 113),\n",
    "    (164, 80, 133),\n",
    "    (83, 122, 114),\n",
    "    (99, 81, 172),\n",
    "    (95, 56, 104),\n",
    "    (37, 84, 86),\n",
    "    (14, 89, 122),\n",
    "    (80, 7, 65),\n",
    "    (10, 102, 25),\n",
    "    (90, 185, 109),\n",
    "    (106, 110, 132),\n",
    "]\n",
    "\n",
    "tmp = []\n",
    "value = 50\n",
    "\n",
    "for i in COLORS:\n",
    "    B = i[0] + value if i[0] + value < 255 else 255\n",
    "    G = i[1] + value if i[1] + value < 255 else 255\n",
    "    R = i[2] + value if i[2] + value < 255 else 255\n",
    "\n",
    "    brightness = (B, G, R)\n",
    "\n",
    "    tmp.append(brightness)\n",
    "\n",
    "COLORS2 = tmp  # Filled Colors\n",
    "\n",
    "\n",
    "# basic transform\n",
    "\"\"\"\n",
    "CAUTION : You must specify the BboxParams.\n",
    "\"\"\"\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "#         albumentations.RandomResizedCrop(224, 224, p=0.5),\n",
    "        albumentations.Resize(512, 512),\n",
    "        albumentations.Normalize(mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25)),\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=albumentations.BboxParams(format=\"pascal_voc\"),\n",
    ")\n",
    "\n",
    "# Simple Dataset Unit Test\n",
    "dataset = RecycleTrashDataset(transform=transform)\n",
    "\n",
    "sample = dataset.__getitem__(0)\n",
    "img = sample[\"img\"].permute(1, 2, 0).detach().cpu().numpy()\n",
    "img = denormalize_image(img, mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25))\n",
    "# cv2.imwrite('./example.jpg', img)\n",
    "# pprint(sample['annot'])\n",
    "\n",
    "\n",
    "# Dataloader Unit Test\n",
    "dataloader = DataLoader(dataset, batch_size=12, shuffle=False, collate_fn=collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05440f7-f068-49da-98af-1e1a3df2002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(dataloader):\n",
    "    for i, batch_sample in enumerate(dataloader):\n",
    "        saved_images = []\n",
    "        imgs, annots = batch_sample[\"img\"], batch_sample[\"annot\"]\n",
    "#         print(\n",
    "#             imgs.shape, annots.shape\n",
    "#         )  # img shape = (batch_size, 3, width, height), annot shape = (batch_size, max_num_bbox, 5(xmin, ymin, xmax, ymax, class label))\n",
    "        img_1, img_2 = (\n",
    "            imgs[0].permute(1, 2, 0).detach().cpu().numpy(),\n",
    "            imgs[1].permute(1, 2, 0).detach().cpu().numpy(),\n",
    "        )\n",
    "        # print(img_1.shape, type(img_1))\n",
    "        for j in range(annots.shape[0]):\n",
    "            output_img = imgs[j].permute(1, 2, 0).detach().cpu().numpy()\n",
    "            output_img = denormalize_image(\n",
    "                output_img, mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25)\n",
    "            )  # denormalize image for visualization\n",
    "            annot = annots[j].detach().cpu().numpy()\n",
    "            for box_id in range(annot.shape[0]):\n",
    "                # if target bbox is just padding -> break\n",
    "                if annot[box_id][-1] < 0:\n",
    "                    break\n",
    "\n",
    "                # for cv2.rectangle arguments type\n",
    "                boxes = np.int64(annot[box_id])\n",
    "\n",
    "                # set class label\n",
    "                label = int(annot[box_id][-1].item())\n",
    "\n",
    "                # set bbox coordinates\n",
    "                xmin, ymin, xmax, ymax = boxes[:4]\n",
    "\n",
    "                # set color\n",
    "                color = COLORS[label]\n",
    "                color2 = COLORS2[label]\n",
    "\n",
    "                # draw bbox\n",
    "                cv2.rectangle(output_img, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "                tmp_img = output_img.copy()\n",
    "                cv2.rectangle(tmp_img, (xmin, ymin), (xmax, ymax), color2, cv2.FILLED)\n",
    "                output_img = cv2.addWeighted(output_img, 0.5, tmp_img, 0.5, 0)\n",
    "                text_size = cv2.getTextSize(CLASSES[label], cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "\n",
    "                cv2.rectangle(\n",
    "                    output_img,\n",
    "                    (xmin, ymin),\n",
    "                    (xmin + text_size[0] + 2, ymin + text_size[1] + 6),\n",
    "                    color,\n",
    "                    -1,\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    output_img,\n",
    "                    CLASSES[label],\n",
    "                    (xmin, ymin + text_size[1] + 4),\n",
    "                    cv2.FONT_ITALIC,\n",
    "                    0.5,\n",
    "                    (255, 255, 255),\n",
    "                    1,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "#             cv2.imwrite(f\"./example_image_{j}.jpg\", output_img)\n",
    "            saved_images.append(output_img)\n",
    "            \n",
    "        yield saved_images\n",
    "    #     print(annots[0].shape, annots[1].shape)\n",
    "    #     pprint(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01aa7b4-cf52-429a-af8f-1371c98df593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_box(single_image):\n",
    "    batch_sample = collater([single_image])\n",
    "    imgs, annots = batch_sample[\"img\"], batch_sample[\"annot\"]\n",
    "#     img_1, img_2 = (\n",
    "#         imgs[0].permute(1, 2, 0).detach().cpu().numpy(),\n",
    "#         imgs[1].permute(1, 2, 0).detach().cpu().numpy(),\n",
    "#     )\n",
    "    # print(img_1.shape, type(img_1))\n",
    "        \n",
    "    for j in range(annots.shape[0]):\n",
    "        output_img = imgs[j].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        output_img = denormalize_image(\n",
    "            output_img, mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25)\n",
    "        )  # denormalize image for visualization\n",
    "        annot = annots[j].detach().cpu().numpy()\n",
    "        for box_id in range(annot.shape[0]):\n",
    "            # if target bbox is just padding -> break\n",
    "            if annot[box_id][-1] < 0:\n",
    "                break\n",
    "\n",
    "            # for cv2.rectangle arguments type\n",
    "            boxes = np.int64(annot[box_id])\n",
    "\n",
    "            # set class label\n",
    "            label = int(annot[box_id][-1].item())\n",
    "\n",
    "            # set bbox coordinates\n",
    "            xmin, ymin, xmax, ymax = boxes[:4]\n",
    "\n",
    "            # set color\n",
    "            color = COLORS[label]\n",
    "            color2 = COLORS2[label]\n",
    "\n",
    "            # draw bbox\n",
    "            cv2.rectangle(output_img, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            tmp_img = output_img.copy()\n",
    "            cv2.rectangle(tmp_img, (xmin, ymin), (xmax, ymax), color2, cv2.FILLED)\n",
    "            output_img = cv2.addWeighted(output_img, 0.5, tmp_img, 0.5, 0)\n",
    "            text_size = cv2.getTextSize(CLASSES[label], cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "\n",
    "            cv2.rectangle(\n",
    "                output_img,\n",
    "                (xmin, ymin),\n",
    "                (xmin + text_size[0] + 2, ymin + text_size[1] + 6),\n",
    "                color,\n",
    "                -1,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                output_img,\n",
    "                CLASSES[label],\n",
    "                (xmin, ymin + text_size[1] + 4),\n",
    "                cv2.FONT_ITALIC,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "#             cv2.imwrite(f\"./example_image_{j}.jpg\", output_img)\n",
    "        return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67e0d7-52c2-4033-b544-38a6435d31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_box(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7ab45-4601-4069-9261-06db23a065c2",
   "metadata": {},
   "source": [
    "# **아래 코드를 반복실행!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456751f-f34d-4197-ac39-6e22f3e4a68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_box = next(gen)\n",
    "\n",
    "image_len = len(images_box)\n",
    "col = 4 # 원하는 값\n",
    "row = math.ceil(image_len / col)\n",
    "figsize = (20, 15)\n",
    "fig, axes = plt.subplots(nrows=row, ncols=col, figsize=figsize)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i >= image_len:\n",
    "        fig.delaxes(ax)\n",
    "        continue\n",
    "    ax.grid(False)\n",
    "#     ax.axis('off')\n",
    "    ax.imshow(images_box[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642f63e-2be7-4d0c-a828-a23f6b9804e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17218032-d31e-4485-bc41-e9f53e64bb3c",
   "metadata": {},
   "source": [
    "# **이미지 하나만 볼때**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2840f-5a2f-4ee6-bd35-a4582728ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = single_image_box(dataset[2616]) # 숫자는 coco에서 얻은 이미지 id\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8d01e-a7a8-4b40-8f01-537266506fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
